from __future__ import annotations

from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from pydantic import BaseModel
from jose import JWTError, jwt
from datetime import datetime, timedelta
from passlib.context import CryptContext
import asyncio, os, redis
from rag_pipline import build_multi_rag, query_multi_rag

# Config
SECRET_KEY = "superankitsecretkey"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/token")

# Mock user DB
fake_users_db = {
    "admin":{
        "username":"admin",
        "hashed_password":pwd_context.hash("User@123"),
    }
}

# Redis Cache
redis_host = os.getenv("REDIS_HOST", "localhost")
redis_port = int(os.getenv("REDIS_PORT", 6379))
redis_ = redis.Redis(host=redis_host, port=redis_port, db=0)

app = FastAPI(title="Multi-Source RAG Service with Auth & Cache")

# Preload RAG Resources

vector_index, bm25, chunks = build_multi_rag()

# Authentication

def verify_password(plain_password, hashed_password):
    return pwd_context.verify(plain_password, hashed_password)

def authenticate_user(username: str, password: str):
    user = fake_users_db.get(username)
    if not user or not verify_password(password, user["hashed_password"]):
        return False
    return user

def create_access_token(data: dict, expires_delta: timedelta | None = None):
    to_encode = data.copy()
    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=15))
    to_encode.update({"exp", expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

@app.post("/token")
async def login(form_data: OAuth2PasswordRequestForm = Depends()):
    user = authenticate_user(form_data.username, form_data.password)
    if not user:
        raise HTTPException(status_code=401, detail="Incorrect username or password")
    access_token = create_access_token(data={"sub": user["username"]},
                                       expires_delta=timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))
    return {"access_token": access_token, "token_type": "bearer"}

async def get_current_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    return username

# RAG Query Endpoint
class QueryRequest(BaseModel):
    query: str

@app.post("/rag/query")
async def rag_query(request: QueryRequest, current_user: str = Depends(get_current_user)):
    cache_key = f"rag:{request.query}"
    cached = redis_.get(cache_key)
    if cached:
        return {"query": request.query, "answer": cached.decode(), "cached":True}

    answer = await asyncio.to_thread(query_multi_rag, request.query, vector_index, bm25, chunks)
    redis_.setex(cache_key, timedelta(hours=1), answer)
    return {"query": request.query, "answer": answer, "cached":False}



"""
ðŸ§  Usage

Start Redis

$ redis-server


Run API

$ uvicorn server:app --reload --port 8000


Authenticate

curl -X POST -d "username=admin&password=User@123" http://localhost:8000/token


â†’ Returns access_token

Query with token

curl -X POST http://localhost:8000/rag/query \
    -H "Authorization: Bearer <token>" \
    -H "Content-Type: application/json" \
    -d '{"query":"Explain microservices communication patterns"}'


The first call stores the answer in Redis; subsequent identical queries are served instantly from cache.
"""

"""

Run everything

In the project root:

docker-compose up --build

| Service      | URL                                                      | Description                 |
| ------------ | -------------------------------------------------------- | --------------------------- |
| FastAPI API  | [http://localhost:8000/docs](http://localhost:8000/docs) | Test secured endpoints      |
| Streamlit UI | [http://localhost:8501](http://localhost:8501)           | Use your RAG assistant      |
| Redis        | Port 6379                                                | Used internally for caching |


| Component | Container   | Port | Purpose                         |
| --------- | ----------- | ---- | ------------------------------- |
| FastAPI   | `rag_api`   | 8000 | Backend API with auth & caching |
| Redis     | `rag_redis` | 6379 | Cache layer                     |
| Streamlit | `rag_ui`    | 8501 | Web UI frontend                 |

"""

"""
| Secret                  | Example value                                |
| ----------------------- | -------------------------------------------- |
| `AWS_ACCESS_KEY_ID`     | your AWS key                                 |
| `AWS_SECRET_ACCESS_KEY` | your AWS secret                              |
| `AWS_REGION`            | us-east-1                                    |
| `ECR_REPOSITORY`        | your-ecr-repository-name                     |
| `ECR_REGISTRY`          | <account-id>.dkr.ecr.us-east-1.amazonaws.com |
| `DOCKERHUB_USERNAME`    | (optional if using DockerHub)                |
| `DOCKERHUB_TOKEN`       | (optional if using DockerHub)                |




multi-rag-observability/
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ main.tf                # Terraform root (Lambda, IAM, Secrets, CloudWatch)
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”œâ”€â”€ lambda.tf              # Lambda + schedule + permissions
â”‚   â”œâ”€â”€ s3.tf                  # Postmortem data bucket
â”‚   â”œâ”€â”€ dynamodb.tf            # Optional: store incident mappings
â”‚   â”œâ”€â”€ grafana.tf             # Optional: Grafana Cloud dashboard provisioning
â”‚   â”œâ”€â”€ redis.tf               # Redis (Elasticache) for caching
â”‚   â”œâ”€â”€ rds.tf                 # PostgreSQL DB for metadata
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ lambdas/
â”‚   â”œâ”€â”€ weekly_digest/
â”‚   â”‚   â”œâ”€â”€ handler.py         # Summarize & send Slack messages
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ dashboard_map.json # Static mapping (can move to DynamoDB)
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collector/
â”‚   â”‚   â”œâ”€â”€ handler.py         # Pull metrics/logs from Grafana, CloudWatch, and Confluence
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_service/
â”‚   â”‚   â”œâ”€â”€ app.py             # FastAPI RAG inference with Redis + Pinecone + PostgreSQL
â”‚   â”‚   â”œâ”€â”€ streamlit_ui.py    # Lightweight UI
â”‚   â”‚   â”œâ”€â”€ ingest_pdfs.py     # PDF/HTML/code extractor
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ rag-service.json   # Grafana dashboard JSON for import
â”‚   â”‚   â””â”€â”€ etl-pipeline.json
â”‚   â””â”€â”€ cloudwatch/
â”‚       â””â”€â”€ metrics-dashboard.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â”œâ”€â”€ INTEGRATIONS.md
â”‚   â”œâ”€â”€ AI_SUMMARIZER_FLOW.md
â”‚   â””â”€â”€ DASHBOARD_MAPPINGS.md
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ benchmark_chunking.py  # Tune RAG chunk size, reranking thresholds
â”‚   â””â”€â”€ api_tests.py           # Test API endpoints
â”‚
â”œâ”€â”€ .env.example
â”œâ”€â”€ Makefile                   # Common commands (terraform init, apply, lambda package)
â””â”€â”€ README.md

"""