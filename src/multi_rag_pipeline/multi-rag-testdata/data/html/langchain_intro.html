LangChain overview - Docs by LangChain Skip to main content We've raised a $125M Series B to build the platform for agent engineering. Read more . Docs by LangChain home page LangChain + LangGraph Search... ⌘ K GitHub Try LangSmith Try LangSmith Search... Navigation LangChain overview LangChain LangGraph Deep Agents Integrations Learn Reference Contribute Python Overview LangChain v1.0 Release notes Migration guide Get started Install Quickstart Philosophy Core components Agents Models Messages Tools Short-term memory Streaming Middleware Structured output Advanced usage Guardrails Runtime Context engineering Model Context Protocol (MCP) Human-in-the-loop Multi-agent Retrieval Long-term memory Use in production Studio Test Deploy Agent Chat UI Observability On this page Install Create an agent Core benefits LangChain overview Copy page Copy page LangChain v1.0 is now available! For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide . If you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content . LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more . LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications. We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph , our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency. LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage. ​ Install pip uv Copy Ask AI pip install -U langchain ​ Create an agent Copy Ask AI # pip install -qU "langchain[anthropic]" to call the model from langchain.agents import create_agent def get_weather ( city : str ) -> str : """Get weather for a given city.""" return f "It's always sunny in { city } !" agent = create_agent( model = "claude-sonnet-4-5-20250929" , tools = [get_weather], system_prompt = "You are a helpful assistant" , ) # Run the agent agent.invoke( { "messages" : [{ "role" : "user" , "content" : "what is the weather in sf" }]} ) ​ Core benefits Standard model interface Different providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in. Learn more Easy to use, highly flexible agent LangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires. Learn more Built on top of LangGraph LangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more. Learn more Debug with LangSmith Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics. Learn more Edit the source of this page on GitHub. Connect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers. Was this page helpful? Yes No What's new in v1 Next ⌘ I Docs by LangChain home page github x linkedin youtube Resources Forum Changelog LangChain Academy Trust Center Company About Careers Blog github x linkedin youtube Powered by Mintlify